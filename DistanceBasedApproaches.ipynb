{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>guid</th>\n",
       "      <th>qu_id</th>\n",
       "      <th>qu</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>qa</th>\n",
       "      <th>ans_id</th>\n",
       "      <th>ans</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>is_correspond</th>\n",
       "      <th>is_useful</th>\n",
       "      <th>f_uq</th>\n",
       "      <th>f_aq</th>\n",
       "      <th>l_uq</th>\n",
       "      <th>l_aq</th>\n",
       "      <th>num_words_uq</th>\n",
       "      <th>num_words_aq</th>\n",
       "      <th>n_common_words</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>fraction_common_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>98550</td>\n",
       "      <td>198647</td>\n",
       "      <td>is lamborghini better than ferrari</td>\n",
       "      <td>198648</td>\n",
       "      <td>why is lamborghini better than ferrari</td>\n",
       "      <td>73400</td>\n",
       "      <td>Lamborghinis.Thats why I have 24 of them compa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23880</td>\n",
       "      <td>122782</td>\n",
       "      <td>what does a trump presidency mean for indian s...</td>\n",
       "      <td>12385</td>\n",
       "      <td>how would trump presidency affect indian stude...</td>\n",
       "      <td>76886</td>\n",
       "      <td>In the last Presidential debate, the conservat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>97</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>108664</td>\n",
       "      <td>210485</td>\n",
       "      <td>why is north america considered the west</td>\n",
       "      <td>210486</td>\n",
       "      <td>is north america considered the west</td>\n",
       "      <td>98240</td>\n",
       "      <td>The British invented the Prime Meridian.  They...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>106306</td>\n",
       "      <td>181906</td>\n",
       "      <td>if you could live in a movie what movie would ...</td>\n",
       "      <td>201042</td>\n",
       "      <td>if you could enter the reality inside a movie ...</td>\n",
       "      <td>74909</td>\n",
       "      <td>Midnight in Paris..!Fantasising about living i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>111</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>103382</td>\n",
       "      <td>518790</td>\n",
       "      <td>what jobs are in art stream</td>\n",
       "      <td>518791</td>\n",
       "      <td>what are scopes of arts stream</td>\n",
       "      <td>129264</td>\n",
       "      <td>You can opt anything as your carrier other tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    guid   qu_id  \\\n",
       "0           0   98550  198647   \n",
       "1           1   23880  122782   \n",
       "2           2  108664  210485   \n",
       "3           3  106306  181906   \n",
       "4           4  103382  518790   \n",
       "\n",
       "                                                  qu   qa_id  \\\n",
       "0                 is lamborghini better than ferrari  198648   \n",
       "1  what does a trump presidency mean for indian s...   12385   \n",
       "2           why is north america considered the west  210486   \n",
       "3  if you could live in a movie what movie would ...  201042   \n",
       "4                        what jobs are in art stream  518791   \n",
       "\n",
       "                                                  qa  ans_id  \\\n",
       "0             why is lamborghini better than ferrari   73400   \n",
       "1  how would trump presidency affect indian stude...   76886   \n",
       "2               is north america considered the west   98240   \n",
       "3  if you could enter the reality inside a movie ...   74909   \n",
       "4                     what are scopes of arts stream  129264   \n",
       "\n",
       "                                                 ans  is_duplicate  \\\n",
       "0  Lamborghinis.Thats why I have 24 of them compa...             1   \n",
       "1  In the last Presidential debate, the conservat...             1   \n",
       "2  The British invented the Prime Meridian.  They...             1   \n",
       "3  Midnight in Paris..!Fantasising about living i...             1   \n",
       "4  You can opt anything as your carrier other tha...             1   \n",
       "\n",
       "   is_correspond  is_useful  f_uq  f_aq  l_uq  l_aq  num_words_uq  \\\n",
       "0              1          1     1     1    36    40             6   \n",
       "1              1          1     2    17    97    61            17   \n",
       "2              1          1     1     1    56    52            10   \n",
       "3              1          1     2     2    63   111            16   \n",
       "4              1          1     1     1    29    32             7   \n",
       "\n",
       "   num_words_aq  n_common_words  total_word_count  fraction_common_words  \n",
       "0             7             6.0              13.0               0.461538  \n",
       "1            11             6.0              28.0               0.214286  \n",
       "2             9             8.0              17.0               0.470588  \n",
       "3            23            10.0              33.0               0.303030  \n",
       "4             7             4.0              14.0               0.285714  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train = pd.read_csv('train.csv')\n",
    "\n",
    "data_frame = pd.read_csv('test.csv')\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qu</th>\n",
       "      <th>qa</th>\n",
       "      <th>ans</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is lamborghini better than ferrari</td>\n",
       "      <td>why is lamborghini better than ferrari</td>\n",
       "      <td>Lamborghinis.Thats why I have 24 of them compa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what does a trump presidency mean for indian s...</td>\n",
       "      <td>how would trump presidency affect indian stude...</td>\n",
       "      <td>In the last Presidential debate, the conservat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why is north america considered the west</td>\n",
       "      <td>is north america considered the west</td>\n",
       "      <td>The British invented the Prime Meridian.  They...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you could live in a movie what movie would ...</td>\n",
       "      <td>if you could enter the reality inside a movie ...</td>\n",
       "      <td>Midnight in Paris..!Fantasising about living i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what jobs are in art stream</td>\n",
       "      <td>what are scopes of arts stream</td>\n",
       "      <td>You can opt anything as your carrier other tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  qu  \\\n",
       "0                 is lamborghini better than ferrari   \n",
       "1  what does a trump presidency mean for indian s...   \n",
       "2           why is north america considered the west   \n",
       "3  if you could live in a movie what movie would ...   \n",
       "4                        what jobs are in art stream   \n",
       "\n",
       "                                                  qa  \\\n",
       "0             why is lamborghini better than ferrari   \n",
       "1  how would trump presidency affect indian stude...   \n",
       "2               is north america considered the west   \n",
       "3  if you could enter the reality inside a movie ...   \n",
       "4                     what are scopes of arts stream   \n",
       "\n",
       "                                                 ans  is_duplicate  \n",
       "0  Lamborghinis.Thats why I have 24 of them compa...             1  \n",
       "1  In the last Presidential debate, the conservat...             1  \n",
       "2  The British invented the Prime Meridian.  They...             1  \n",
       "3  Midnight in Paris..!Fantasising about living i...             1  \n",
       "4  You can opt anything as your carrier other tha...             1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = data_frame[data_frame.is_correspond !=0] #remove rows where is_correspond equal to zero(is_correspond\twhether `ans' is the answer of `qa')\n",
    "data_frame = data_frame[data_frame.is_duplicate !=0] #choosing only rows which contains dupliacte questions\n",
    "QApair_df = data_frame[['qu','qa','ans','is_duplicate']].copy() #getting archived question and anser\n",
    "QApair_df = QApair_df[:500]\n",
    "QApair_df.to_csv('QnA.csv')\n",
    "print(QApair_df.shape)\n",
    "QApair_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arch_questions = QApair_df['qa'].tolist() #list of questions\n",
    "all_user_questions = QApair_df['qu'].tolist() #list of user questions\n",
    "all_answers  = QApair_df['ans'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "all_questions = [] #getting all questions in the  training set for building vocabulary\n",
    "for i,entry in tfidf_train.iterrows():\n",
    "    aq=entry['qa']\n",
    "    uq = entry['qu']\n",
    "    if repr(aq)==\"NaN\":\n",
    "        print('Spotted a NaN object')\n",
    "        pass\n",
    "    else:\n",
    "        all_questions.append(aq)\n",
    "    if repr(uq)==\"NaN\":\n",
    "        print('Spotted a NaN object')\n",
    "        pass\n",
    "    else:\n",
    "        all_questions.append(uq)\n",
    "print(len(all_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "vectorizer = TfidfVectorizer(max_features = 8000)\n",
    "vect_vocab = vectorizer.fit(all_questions)\n",
    "user_quest_vecs = vect_vocab.transform(all_user_questions)\n",
    "arch_quest_vecs = vect_vocab.transform(all_arch_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 8000)\n",
      "(500, 8000)\n"
     ]
    }
   ],
   "source": [
    "print(user_quest_vecs.shape)\n",
    "print(arch_quest_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 1598815193.1805632\n",
      "Execution time: 153.7899203300476\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(\"start time:\",start_time)\n",
    "max_similarity_val = 0\n",
    "tfidf_reciprocal_rank_list = []\n",
    "for uquest_id, uq in enumerate(user_quest_vecs):\n",
    "    similarity_scores = []\n",
    "    most_similar_quest_id = 0\n",
    "    for aq in arch_quest_vecs:        \n",
    "        similarity_scores.append(cosine_similarity(uq,aq))# geting similarity scores of user question with each archived question\n",
    "    most_similar_quest_id = np.argmax(np.array(similarity_scores))\n",
    "    if all_arch_questions[uquest_id]==all_arch_questions[most_similar_quest_id]:\n",
    "        #print(\"Most similar question retrieved\")\n",
    "        tfidf_reciprocal_rank_list.append(1)\n",
    "    else:\n",
    "        #print(\"Dissimilar question retrived\")\n",
    "        tfidf_reciprocal_rank_list.append(0)\n",
    "    #print(\"User Question:\",all_user_questions[uquest_id])\n",
    "    #print(\"Archived Question\",all_arch_questions[uquest_id])\n",
    "    #print(\"Retrieved Question\",all_arch_questions[most_similar_quest_id])\n",
    "    #if uquest_id==10:\n",
    "        #break\n",
    "end_time = time.time()\n",
    "print(\"Execution time:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank:  0.936\n",
      "Number of question correctly retreived:  468\n"
     ]
    }
   ],
   "source": [
    "tfidf_mean_reciprocal_rank = np.mean(np.array(tfidf_reciprocal_rank_list)) \n",
    "print(\"Mean Reciprocal Rank: \",tfidf_mean_reciprocal_rank)\n",
    "print(\"Number of question correctly retreived: \", sum(tfidf_reciprocal_rank_list) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained word2vec(google news vectors)\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from pathlib import Path\n",
    "path_of_downloaded_bin = Path(\"C:\\\\Users\\\\ASUS\\\\NLP\\\\embeddings\\\\GoogleNews-vectors-negative300.bin\")\n",
    "word_vectors = KeyedVectors.load_word2vec_format(datapath(path_of_downloaded_bin), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_vec_dim = 300 # this number should match the embedding used, this is the embedding size\n",
    "oov_vec = np.zeros(word_vec_dim)   #random vectoor , use if the given word is not present in the vocabulary\n",
    "def vectorize_sent(word_vectors, sent):\n",
    "    word_vecs = []\n",
    "    for token in word_tokenize(sent): \n",
    "        if token not in word_vectors: \n",
    "            word_vecs.append(oov_vec)\n",
    "        else:\n",
    "            word_vecs.append(word_vectors[token].astype('float64'))\n",
    "    return (np.mean(word_vecs,axis=0)).reshape(1,-1)\n",
    "\n",
    "sent = vectorize_sent(word_vectors, 'hello world ! this is a test sentence !') #testing\n",
    "print(sent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_user_quest =  np.array([vectorize_sent(word_vectors, ss) for ss in all_user_questions]) #embedding for all user questions\n",
    "word2vec_user_quest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_arch_quest = np.array([vectorize_sent(word_vectors, ss) for ss in all_arch_questions]) #embedding for all archived questions\n",
    "word2vec_arch_quest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_vectors #deleting word vectors to free the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 1598812699.1462665\n",
      "Execution time: 45.72040128707886\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(\"start time:\",start_time)\n",
    "max_similarity_val = 0 \n",
    "wv_reciprocal_rank_list = [] #initialize list\n",
    "for uquest_id, uq in enumerate(word2vec_user_quest):\n",
    "    #print(uquest_id)\n",
    "    similarity_scores = []\n",
    "    most_similar_quest_id = 0\n",
    "    for aq in word2vec_arch_quest:        \n",
    "        similarity_scores.append(cosine_similarity(uq,aq))# geting similarity scores of user question with each archived question\n",
    "    most_similar_quest_id = np.argmax(np.array(similarity_scores))\n",
    "    if all_arch_questions[uquest_id]==all_arch_questions[most_similar_quest_id]:\n",
    "        #print(\"Most similar question retrieved\")\n",
    "        wv_reciprocal_rank_list.append(1)\n",
    "    else:\n",
    "        #print(\"Dissimilar question retrived\")\n",
    "        wv_reciprocal_rank_list.append(0)\n",
    "    #print(\"User Question:\",all_user_questions[uquest_id])\n",
    "    #print(\"Archived Question\",all_arch_questions[uquest_id])\n",
    "    #print(\"Retrieved Question\",all_arch_questions[most_similar_quest_id])\n",
    "    #if uquest_id==10:\n",
    "        #break\n",
    "end_time = time.time()\n",
    "print(\"Execution time:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank for Word2vec embedding:  0.88\n",
      "Number of question correctly retreived for Word2Vec Embedding:  440\n"
     ]
    }
   ],
   "source": [
    "wv_mean_reciprocal_rank = np.mean(np.array(wv_reciprocal_rank_list))\n",
    "print(\"Mean Reciprocal Rank for Word2vec embedding: \",wv_mean_reciprocal_rank)\n",
    "print(\"Number of question correctly retreived for Word2Vec Embedding: \", sum(wv_reciprocal_rank_list) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# here I load the 300-dimension vectors; loading longer embeddings would require longer time and more RAM\n",
    "path_of_downloaded_files = \"C:\\\\Users\\\\ASUS\\\\NLP\\\\embeddings\\\\glove.6B\\\\glove.6B.300d.txt\" \n",
    "\n",
    "glove_file = datapath(path_of_downloaded_files)\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.300d.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_dim = 300 # this number should match the embedding used\n",
    "oov_vec = np.zeros(word_vec_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_user_quest =  np.array([vectorize_sent(word_vectors, ss) for ss in all_user_questions]) #embedding for all user questions\n",
    "glove_user_quest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_arch_quest = np.array([vectorize_sent(word_vectors, ss) for ss in all_arch_questions]) #embedding for all archived questions\n",
    "glove_arch_quest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 1598812860.028137\n",
      "Execution time: 49.66813588142395\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(\"start time:\",start_time)\n",
    "glove_reciprocal_rank_list = []\n",
    "for uquest_id, uq in enumerate(glove_user_quest):\n",
    "    #print(uquest_id)\n",
    "    similarity_scores = []\n",
    "    most_similar_quest_id = 0\n",
    "    for aq in glove_arch_quest:        \n",
    "        similarity_scores.append(cosine_similarity(uq,aq))# geting similarity scores of user question with each archived question\n",
    "    most_similar_quest_id = np.argmax(np.array(similarity_scores))\n",
    "    if all_arch_questions[uquest_id]==all_arch_questions[most_similar_quest_id]:\n",
    "        #print(\"Most similar question retrieved\")\n",
    "        glove_reciprocal_rank_list.append(1)\n",
    "    else:\n",
    "        #print(\"Dissimilar question retrived\")\n",
    "        glove_reciprocal_rank_list.append(0)\n",
    "    #print(\"User Question:\",all_user_questions[uquest_id])\n",
    "    #print(\"Archived Question\",all_arch_questions[uquest_id])\n",
    "    #print(\"Retrieved Question\",all_arch_questions[most_similar_quest_id])\n",
    "    #if uquest_id==10:\n",
    "        #break\n",
    "end_time = time.time()\n",
    "print(\"Execution time:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank for Glove embedding:  0.806\n",
      "Number of question correctly retreived for Glove Embedding:  403\n"
     ]
    }
   ],
   "source": [
    "glove_mean_reciprocal_rank = np.mean(np.array(glove_reciprocal_rank_list))\n",
    "print(\"Mean Reciprocal Rank for Glove embedding: \",glove_mean_reciprocal_rank)\n",
    "print(\"Number of question correctly retreived for Glove Embedding: \", sum(glove_reciprocal_rank_list) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT embedding (bert-as-service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prerequisites \n",
    "#pip install bert-serving-server  # server\n",
    "#pip install bert-serving-client  # client, independent of `bert-serving-server`\n",
    "\n",
    "#to run this we need to start bert server from the command prompt\n",
    "#got to anaconda prompt\n",
    "#activate virtual environment , if you are using a virtual environment for running this code\n",
    "#run the command\n",
    "#bert-serving-start -model_dir C:\\Users\\ASUS\\NLP\\embeddings\\uncased_L-12_H-768_A-12 -num_worker 1\n",
    "\n",
    "#C:\\Users\\ASUS\\NLP\\embeddings\\uncased_L-12_H-768_A-127 this is the folder to which i downloaded the pretrained BERT, you can download it from\n",
    "\n",
    "#https://github.com/google-research/bert#pre-trained-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient(check_length=False)\n",
    "res=bc.encode(['hello How are you', ' How old are you']) #testing\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1, 768)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_user_quest = np.array([bc.encode([ss]) for ss in all_user_questions]) \n",
    "bert_user_quest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1, 768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_arch_quest = np.array([bc.encode([ss]) for ss in all_arch_questions])\n",
    "bert_arch_quest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 1598813006.165855\n",
      "Execution time: 53.85407829284668\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(\"start time:\",start_time)\n",
    "max_similarity_val = 0\n",
    "bert_reciprocal_rank_list = []\n",
    "for uquest_id, uq in enumerate(bert_user_quest):\n",
    "    #print(uquest_id)\n",
    "    similarity_scores = []\n",
    "    most_similar_quest_id = 0\n",
    "    for aq in bert_arch_quest:        \n",
    "        similarity_scores.append(cosine_similarity(uq,aq))# geting similarity scores of user question with each archived question\n",
    "    most_similar_quest_id = np.argmax(np.array(similarity_scores))\n",
    "    if all_arch_questions[uquest_id]==all_arch_questions[most_similar_quest_id]:\n",
    "        #print(\"Most similar question retrieved\")\n",
    "        bert_reciprocal_rank_list.append(1)\n",
    "    else:\n",
    "        #print(\"Dissimilar question retrived\")\n",
    "        bert_reciprocal_rank_list.append(0)\n",
    "    #print(\"User Question:\",all_user_questions[uquest_id])\n",
    "    #print(\"Archived Question\",all_arch_questions[uquest_id])\n",
    "    #print(\"Retrieved Question\",all_arch_questions[most_similar_quest_id])\n",
    "    #if uquest_id==10:\n",
    "        #break\n",
    "end_time = time.time()\n",
    "print(\"Execution time:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank for Bert embedding:  0.754\n",
      "Number of question correctly retreived for Bert Embedding:  377\n"
     ]
    }
   ],
   "source": [
    "bert_mean_reciprocal_rank = np.mean(np.array(bert_reciprocal_rank_list))\n",
    "print(\"Mean Reciprocal Rank for Bert embedding: \",bert_mean_reciprocal_rank)\n",
    "print(\"Number of question correctly retreived for Bert Embedding: \", sum(bert_reciprocal_rank_list) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')# pretrained modellist availble at fromhttps://docs.google.com/spreadsheets/d/14QplCdTCDwEmTqrn1LH4yrbKvdogK4oQvYO1K1aPR5M/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_user_quest = np.array(model.encode(all_user_questions))\n",
    "bert_user_quest = bert_user_quest.reshape(len(all_user_questions),1,768)\n",
    "bert_user_quest[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_arch_quest = np.array(model.encode(all_arch_questions))\n",
    "bert_arch_quest = bert_arch_quest.reshape(len(all_arch_questions),1,768)\n",
    "bert_arch_quest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 1598813081.8866365\n",
      "Execution time: 50.8556489944458\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(\"start time:\",start_time)\n",
    "max_similarity_val = 0\n",
    "sbert_reciprocal_rank_list = []\n",
    "for uquest_id, uq in enumerate(bert_user_quest):\n",
    "    #print(uquest_id)\n",
    "    similarity_scores = []\n",
    "    most_similar_quest_id = 0\n",
    "    for aq in bert_arch_quest:        \n",
    "        similarity_scores.append(cosine_similarity(np.array(uq),np.array(aq)))# geting similarity scores of user question with each archived question\n",
    "    most_similar_quest_id = np.argmax(np.array(similarity_scores))\n",
    "    if all_arch_questions[uquest_id]==all_arch_questions[most_similar_quest_id]:\n",
    "        #print(\"Most similar question retrieved\")\n",
    "        sbert_reciprocal_rank_list.append(1)\n",
    "    else:\n",
    "        #print(\"Dissimilar question retrived\")\n",
    "        sbert_reciprocal_rank_list.append(0)\n",
    "    #print(\"User Question:\",all_user_questions[uquest_id])\n",
    "    #print(\"Archived Question\",all_arch_questions[uquest_id])\n",
    "    #print(\"Retrieved Question\",all_arch_questions[most_similar_quest_id])\n",
    "    #if uquest_id==10:\n",
    "        #break\n",
    "end_time = time.time()\n",
    "print(\"Execution time:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank for Bert embedding:  0.858\n",
      "Number of question correctly retreived for Bert Embedding:  429\n"
     ]
    }
   ],
   "source": [
    "sbert_mean_reciprocal_rank = np.mean(np.array(sbert_reciprocal_rank_list))\n",
    "print(\"Mean Reciprocal Rank for Bert embedding: \",sbert_mean_reciprocal_rank)\n",
    "print(\"Number of question correctly retreived for Bert Embedding: \", sum(sbert_reciprocal_rank_list) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorization_method</th>\n",
       "      <th>mean_reciprocal_ranks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Word2vec</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glove</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bert-as-service</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBERT</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vectorization_method  mean_reciprocal_ranks\n",
       "0               tf-idf                  0.936\n",
       "1             Word2vec                  0.880\n",
       "2                Glove                  0.806\n",
       "3      Bert-as-service                  0.754\n",
       "4                SBERT                  0.858"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing different models\n",
    "mrr_df = pd.DataFrame()\n",
    "mrr_df[\"vectorization_method\"] = [\"tf-idf\",\"Word2vec\",\"Glove\",\"Bert-as-service\", \"SBERT\"]\n",
    "mrr_df[\"mean_reciprocal_ranks\"] = [tfidf_mean_reciprocal_rank,wv_mean_reciprocal_rank,glove_mean_reciprocal_rank,bert_mean_reciprocal_rank,sbert_mean_reciprocal_rank]\n",
    "mrr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4],\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(mrr_df[\"vectorization_method\"],mrr_df[\"mean_reciprocal_ranks\"])\n",
    "plt.ylabel(\"Mean Reciprocal rank\")\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(rotation = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vevn_nlp",
   "language": "python",
   "name": "vevn_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
