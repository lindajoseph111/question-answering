{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from pathlib import Path\n",
    "import math\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression+ Basic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>guid</th>\n",
       "      <th>qu_id</th>\n",
       "      <th>qu</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>qa</th>\n",
       "      <th>ans_id</th>\n",
       "      <th>ans</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>is_correspond</th>\n",
       "      <th>is_useful</th>\n",
       "      <th>f_uq</th>\n",
       "      <th>f_aq</th>\n",
       "      <th>l_uq</th>\n",
       "      <th>l_aq</th>\n",
       "      <th>num_words_uq</th>\n",
       "      <th>num_words_aq</th>\n",
       "      <th>n_common_words</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>fraction_common_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>3602</td>\n",
       "      <td>198978</td>\n",
       "      <td>38298</td>\n",
       "      <td>why is pakistan denying the surgical strike</td>\n",
       "      <td>186810</td>\n",
       "      <td>what is the reason behind pakistan denying the...</td>\n",
       "      <td>51851</td>\n",
       "      <td>Because in war isn't that what the enemy is su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6619</th>\n",
       "      <td>5307</td>\n",
       "      <td>300387</td>\n",
       "      <td>243337</td>\n",
       "      <td>what would be your reaction if you discovered ...</td>\n",
       "      <td>243338</td>\n",
       "      <td>do you put money under your children s pillows...</td>\n",
       "      <td>226510</td>\n",
       "      <td>The Tooth Fairy brings magic (and money) to a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7853</th>\n",
       "      <td>7807</td>\n",
       "      <td>192703</td>\n",
       "      <td>110216</td>\n",
       "      <td>how do i convert mp3 file to midi file</td>\n",
       "      <td>172955</td>\n",
       "      <td>is there a way to convert an audio file mp3 or...</td>\n",
       "      <td>146804</td>\n",
       "      <td>Bear File Converter.It helps you to convert Mp...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>7720</td>\n",
       "      <td>200389</td>\n",
       "      <td>171871</td>\n",
       "      <td>is it possible the 2016 u s presidential elect...</td>\n",
       "      <td>171872</td>\n",
       "      <td>how is it possible to rig the 2016 election</td>\n",
       "      <td>146172</td>\n",
       "      <td>Easy, just keep telling people over and over a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>5023</td>\n",
       "      <td>128745</td>\n",
       "      <td>394582</td>\n",
       "      <td>is google about to thrive or decline in the co...</td>\n",
       "      <td>62387</td>\n",
       "      <td>what year was google founded</td>\n",
       "      <td>24410</td>\n",
       "      <td>Google was founded on 4th September, 1998.Google</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    guid   qu_id  \\\n",
       "879         3602  198978   38298   \n",
       "6619        5307  300387  243337   \n",
       "7853        7807  192703  110216   \n",
       "1943        7720  200389  171871   \n",
       "6485        5023  128745  394582   \n",
       "\n",
       "                                                     qu   qa_id  \\\n",
       "879         why is pakistan denying the surgical strike  186810   \n",
       "6619  what would be your reaction if you discovered ...  243338   \n",
       "7853             how do i convert mp3 file to midi file  172955   \n",
       "1943  is it possible the 2016 u s presidential elect...  171872   \n",
       "6485  is google about to thrive or decline in the co...   62387   \n",
       "\n",
       "                                                     qa  ans_id  \\\n",
       "879   what is the reason behind pakistan denying the...   51851   \n",
       "6619  do you put money under your children s pillows...  226510   \n",
       "7853  is there a way to convert an audio file mp3 or...  146804   \n",
       "1943        how is it possible to rig the 2016 election  146172   \n",
       "6485                       what year was google founded   24410   \n",
       "\n",
       "                                                    ans  is_duplicate  \\\n",
       "879   Because in war isn't that what the enemy is su...             1   \n",
       "6619  The Tooth Fairy brings magic (and money) to a ...             0   \n",
       "7853  Bear File Converter.It helps you to convert Mp...             0   \n",
       "1943  Easy, just keep telling people over and over a...             1   \n",
       "6485   Google was founded on 4th September, 1998.Google             0   \n",
       "\n",
       "      is_correspond  is_useful  f_uq  f_aq  l_uq  l_aq  num_words_uq  \\\n",
       "879               1          1     2     3    45    74             8   \n",
       "6619              1          0     1     1   101    71            19   \n",
       "7853              1          0     4     1    40    71            10   \n",
       "1943              1          1     1     1    98    45            19   \n",
       "6485              1          0     1     1    58    30            12   \n",
       "\n",
       "      num_words_aq  n_common_words  total_word_count  fraction_common_words  \n",
       "879             13             6.0              20.0               0.300000  \n",
       "6619            14             5.0              32.0               0.156250  \n",
       "7853            19             6.0              25.0               0.240000  \n",
       "1943            10             9.0              23.0               0.391304  \n",
       "6485             6             2.0              18.0               0.111111  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QApair_df = pd.read_csv('train.csv')\n",
    "QApair_df = shuffle(QApair_df)\n",
    "QApair_df = QApair_df.dropna() #dropping na\n",
    "QApair_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_downloaded_bin = Path(\"C:\\\\Users\\\\ASUS\\\\NLP\\\\embeddings\\\\GoogleNews-vectors-negative300.bin\")\n",
    "word_vectors = KeyedVectors.load_word2vec_format(datapath(path_of_downloaded_bin), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_dim = 300 # this number should match the embedding used\n",
    "oov_vec = np.random.rand(word_vec_dim) \n",
    "def vectorize_sent(word_vectors, sent):\n",
    "    word_vecs = []\n",
    "    for token in word_tokenize(sent):\n",
    "        if token not in word_vectors: \n",
    "            word_vecs.append(oov_vec)\n",
    "        else:\n",
    "            word_vecs.append(word_vectors[token].astype('float64'))\n",
    "    return (np.mean(word_vecs,axis=0)).reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with concatenated sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of x_data: 8000\n",
      "length of y_data: 8000\n"
     ]
    }
   ],
   "source": [
    "QApair_df[\"concat_text\"] = QApair_df['qu']+' '+ QApair_df['qa'] #training data is cocatenated sentences\n",
    "QApair_df = shuffle(QApair_df)\n",
    "x_data = QApair_df[\"concat_text\"]\n",
    "y_data = QApair_df['is_duplicate'] #list of labels\n",
    "\n",
    "print(\"length of x_data:\",len(x_data))\n",
    "print(\"length of y_data:\",len(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in x_data]) #vector of concatenated questions\n",
    "x_data_vecs = x_data_vecs.reshape(len(x_data),word_vec_dim) #reshaping the array from 3d to 2d"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Fine tuning Logistic regression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipe = Pipeline([(\"clf\",LogisticRegression())])\n",
    "param_grid = [{\"clf__C\":[0.1,1.0,10.0],\"clf__class_weight\":['dict','balanced'],\"clf__solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \"clf__max_iter\": [1000,2000,5000,10000]}]\n",
    "gs = GridSearchCV(pipe,param_grid,scoring = \"accuracy\",cv = 5, verbose = 1, n_jobs = -1)\n",
    "gs.fit(x_data_vecs,y_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"Best Params\",gs.best_params_)\n",
    "print(\"Best score\",gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = 1.0,class_weight = 'dict', max_iter = 1000,solver = 'newton-cg').fit(x_data_vecs, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of archived Questions: 500\n"
     ]
    }
   ],
   "source": [
    "#finding mean reciprocal rank:\n",
    "test_df_ml = pd.read_csv('test.csv') #getting the test data\n",
    "test_df_ml = test_df_ml[['qu','qa','is_duplicate']].copy()\n",
    "test_df_ml = test_df_ml[:500]\n",
    "l = len(test_df_ml['qa'])#Number of archived Questions\n",
    "print(\"Number of archived Questions:\",l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_questions = test_df_ml['qu'].tolist()\n",
    "concat_reciprocal_rank_list = []\n",
    "arch_questions = test_df_ml['qa'].tolist()\n",
    "l = len(arch_questions)\n",
    "for uquest_id, user_quest in enumerate(user_questions):\n",
    "    most_similar_quest_id = 0\n",
    "    test_ml = test_df_ml[['qa']].copy()\n",
    "    test_ml['qu'] = [user_quest]*l\n",
    "    test_ml['concat_text'] = test_ml['qu']+' '+ test_ml['qa']\n",
    "    test_x_data = test_ml[\"concat_text\"]\n",
    "    test_xdata_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in test_x_data.tolist()])\n",
    "    test_xdata_vecs = test_xdata_vecs.reshape(len(arch_questions),word_vec_dim)\n",
    "    y_pred = clf.predict_proba(test_xdata_vecs) #predict probability\n",
    "    y_max = y_pred[:,0] #selecting only probability of duplication\n",
    "    most_similar_quest_id = np.argmax(np.array(y_max))\n",
    "    if arch_questions[uquest_id] ==arch_questions[most_similar_quest_id]:#comparing the retreived with duplicate question of user question\n",
    "        #print(\"\\nMost similar question retrieved\")\n",
    "        concat_reciprocal_rank_list.append(1)\n",
    "    else:\n",
    "        #print(\"\\nDissimilar question retrived\")\n",
    "        concat_reciprocal_rank_list.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank for ML+Cosine similiarity  0.0\n",
      "Number of question correctly retreived for Bert Embedding:  0\n"
     ]
    }
   ],
   "source": [
    "concat_mean_reciprocal_rank = np.mean(np.array(concat_reciprocal_rank_list))\n",
    "print(\"Mean Reciprocal Rank for ML+Cosine similiarity \",concat_mean_reciprocal_rank)\n",
    "print(\"Number of question correctly retreived for Bert Embedding: \", sum(concat_reciprocal_rank_list) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML+Word Embeddings Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all text size 8000\n",
      "All label size 8000\n"
     ]
    }
   ],
   "source": [
    "all_text = QApair_df[[\"qu\",\"qa\"]]\n",
    "all_labels = QApair_df[\"is_duplicate\"]\n",
    "print(\"all text size\", len(all_text))\n",
    "print(\"All label size\", len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_text = all_text[\"qu\"].tolist()\n",
    "all_arch_text = all_text[\"qa\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#following embeddingds are used for finding diff distances between question pairs of all vectors\n",
    "all_user_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in all_user_text]) #getting vector representation for user questions\n",
    "all_arch_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in all_arch_text]) #getting vector representation for archived questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = all_user_vecs-all_arch_vecs\n",
    "x_data = x_data.reshape(len(all_user_text),word_vec_dim)\n",
    "y_data = all_labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Fine tuning Logistic regression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipe = Pipeline([(\"clf\",LogisticRegression())])\n",
    "param_grid = [{\"clf__C\":[0.1,1.0,10.0],\"clf__class_weight\":['dict','balanced'],\"clf__solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \"clf__max_iter\": [1000,2000,5000,10000]}]\n",
    "gs = GridSearchCV(pipe,param_grid,scoring = \"accuracy\",cv = 5, verbose = 1, n_jobs = -1)\n",
    "gs.fit(x_data,y_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"Best Params\",gs.best_params_)\n",
    "print(\"Best score\",gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = 1.0,class_weight = 'dict',max_iter  = 1000,solver = 'sag').fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of archived Questions: 500\n"
     ]
    }
   ],
   "source": [
    "#finding mean reciprocal rank:\n",
    "test_df_ml = pd.read_csv('test.csv') #getting the test data\n",
    "test_df_ml = test_df_ml[['qu','qa','is_duplicate']].copy()\n",
    "test_df_ml = test_df_ml[:500]\n",
    "l = len(test_df_ml['qa'])#Number of archived Questions\n",
    "print(\"Number of archived Questions:\",l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_reciprocal_rank_list = []\n",
    "most_similar_quest_id = 0\n",
    "user_questions = test_df_ml['qu'].tolist()\n",
    "arch_questions = test_df_ml['qa'].tolist()\n",
    "test_user_vecs_ml = np.array([vectorize_sent(word_vectors, ss) for ss in user_questions]) #getting vector representation for user questions\n",
    "test_arch_vecs_ml = np.array([vectorize_sent(word_vectors, ss) for ss in arch_questions]) #getting vector representation for archived questions\n",
    "for uquest_id, user_quest in enumerate(test_user_vecs_ml):\n",
    "    user_vecs = np.array([user_quest]*l) #making the dimesion of user vecs same as arch vecs\n",
    "    test_x_data = user_vecs-test_arch_vecs_ml #finding difference between user question vectors and archived question \n",
    "    test_x_data = test_x_data.reshape(l,word_vec_dim)\n",
    "    y_pred = clf.predict_proba(test_x_data) #predict probability\n",
    "    y_max = y_pred[:,1] #selecting only probability of duplication\n",
    "    most_similar_quest_id = np.argmax(np.array(y_max))\n",
    "    most_similar_quest_id\n",
    "    if arch_questions[uquest_id] ==arch_questions[most_similar_quest_id]:#comparing the retreived with duplicate question of user question\n",
    "        #print(\"\\nMost similar question retrieved\")\n",
    "        diff_reciprocal_rank_list.append(1)\n",
    "    else:\n",
    "        #print(\"\\nDissimilar question retrived\")\n",
    "        diff_reciprocal_rank_list.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank for Ml+diff of embeddings  0.002\n",
      "Number of question correctly retreived for Ml+diff of embeddings:  1\n"
     ]
    }
   ],
   "source": [
    "diff_mean_reciprocal_rank = np.mean(np.array(diff_reciprocal_rank_list))\n",
    "print(\"Mean Reciprocal Rank for Ml+diff of embeddings \",diff_mean_reciprocal_rank)\n",
    "print(\"Number of question correctly retreived for Ml+diff of embeddings: \", sum(diff_reciprocal_rank_list) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>mean_reciprocal_ranks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR+ConcatQuestions</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR+Difference of vectors</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Method  mean_reciprocal_ranks\n",
       "0        LR+ConcatQuestions                  0.000\n",
       "1  LR+Difference of vectors                  0.002"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df[\"Method\"] = [\"LR+ConcatQuestions\",\"LR+Difference of vectors\"]\n",
    "results_df[\"mean_reciprocal_ranks\"] = [concat_mean_reciprocal_rank,diff_mean_reciprocal_rank]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1], [Text(0, 0, ''), Text(0, 0, '')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(results_df[\"Method\"],results_df[\"mean_reciprocal_ranks\"])\n",
    "plt.ylabel(\"Mean Reciprocal rank\")\n",
    "plt.ylim(0.5,1)\n",
    "plt.xticks(rotation = 45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vevn_nlp",
   "language": "python",
   "name": "vevn_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
