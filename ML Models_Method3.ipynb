{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from pathlib import Path\n",
    "import math\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_word_Common(sample):\n",
    "    \"\"\"finding number of words common in both user question and archived Question\"\"\"\n",
    "    uq = set(map(lambda w: w.lower().strip(), sample['qu'].split(\" \")))\n",
    "    aq = set(map(lambda w: w.lower().strip(), sample['qa'].split(\" \")))    \n",
    "    return len(uq & aq)*1.0\n",
    "\n",
    "def find_total_word_count(sample):\n",
    "    \"\"\"Finding total number of words in both user and archived questions\"\"\"\n",
    "    uq = set(map(lambda w: w.lower().strip(), sample['qu'].split(\" \")))\n",
    "    aq = set(map(lambda w: w.lower().strip(), sample['qa'].split(\" \")))   \n",
    "    return (len(uq) + len(aq))*1.0\n",
    "#test_ml['total_word_count'] = test_ml.apply(find_total_word_count, axis=1)\n",
    "\n",
    "def fraction_common_words(sample):\n",
    "    \"\"\"Finding the ratio of the number of words in common and total number of words in user and archived questions\"\"\"\n",
    "    uq = set(map(lambda w: w.lower().strip(), sample['qu'].split(\" \")))\n",
    "    aq = set(map(lambda w: w.lower().strip(), sample['qa'].split(\" \"))) \n",
    "    return 1.0 * len(uq & aq)/(len(uq) + len(aq))\n",
    "#test_ml['fraction_common_words'] = test_ml.apply(fraction_common_words, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating sigmoid score\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Method3: Probabilistic classifier+Word2vec for distance feature+Cosine Sim+Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>guid</th>\n",
       "      <th>qu_id</th>\n",
       "      <th>qu</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>qa</th>\n",
       "      <th>ans_id</th>\n",
       "      <th>ans</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>is_correspond</th>\n",
       "      <th>is_useful</th>\n",
       "      <th>f_uq</th>\n",
       "      <th>f_aq</th>\n",
       "      <th>l_uq</th>\n",
       "      <th>l_aq</th>\n",
       "      <th>num_words_uq</th>\n",
       "      <th>num_words_aq</th>\n",
       "      <th>n_common_words</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>fraction_common_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>3589</td>\n",
       "      <td>129727</td>\n",
       "      <td>100851</td>\n",
       "      <td>what is the salary of indian foreign service o...</td>\n",
       "      <td>100852</td>\n",
       "      <td>what is the salary of an indian foreign servic...</td>\n",
       "      <td>32525</td>\n",
       "      <td>While working in India, an IFS officer can dra...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>4819</td>\n",
       "      <td>3892</td>\n",
       "      <td>172683</td>\n",
       "      <td>what would happen to british empire and its ef...</td>\n",
       "      <td>172684</td>\n",
       "      <td>what would happen if indian people had succeed...</td>\n",
       "      <td>146655</td>\n",
       "      <td>The currency in circulation probably would hav...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>125</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    guid   qu_id  \\\n",
       "876         3589  129727  100851   \n",
       "1176        4819    3892  172683   \n",
       "\n",
       "                                                     qu   qa_id  \\\n",
       "876   what is the salary of indian foreign service o...  100852   \n",
       "1176  what would happen to british empire and its ef...  172684   \n",
       "\n",
       "                                                     qa  ans_id  \\\n",
       "876   what is the salary of an indian foreign servic...   32525   \n",
       "1176  what would happen if indian people had succeed...  146655   \n",
       "\n",
       "                                                    ans  is_duplicate  \\\n",
       "876   While working in India, an IFS officer can dra...             1   \n",
       "1176  The currency in circulation probably would hav...             1   \n",
       "\n",
       "      is_correspond  is_useful  f_uq  f_aq  l_uq  l_aq  num_words_uq  \\\n",
       "876               1          1     1     2    54    57            10   \n",
       "1176              1          1     1     1   141   125            25   \n",
       "\n",
       "      num_words_aq  n_common_words  total_word_count  fraction_common_words  \n",
       "876             11            10.0              21.0               0.476190  \n",
       "1176            23            16.0              45.0               0.355556  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QApair_df = pd.read_csv('train.csv')\n",
    "QApair_df = shuffle(QApair_df)\n",
    "QApair_df = QApair_df.dropna() #dropping na\n",
    "QApair_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all text size 8000\n",
      "All label size 8000\n"
     ]
    }
   ],
   "source": [
    "all_text = QApair_df[[\"qu\",\"qa\"]]\n",
    "all_labels = QApair_df[\"is_duplicate\"]\n",
    "print(\"all text size\", len(all_text))\n",
    "print(\"All label size\", len(all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_text = all_text[\"qu\"].tolist() #\n",
    "all_arch_text = all_text[\"qa\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_vectors\n",
    "path_of_downloaded_bin = Path(\"C:\\\\Users\\\\ASUS\\\\NLP\\\\embeddings\\\\GoogleNews-vectors-negative300.bin\")\n",
    "word_vectors = KeyedVectors.load_word2vec_format(datapath(path_of_downloaded_bin), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_dim = 300 # this number should match the embedding used\n",
    "oov_vec = np.random.rand(word_vec_dim) \n",
    "def vectorize_sent(word_vectors, sent):\n",
    "    word_vecs = []\n",
    "    for token in word_tokenize(sent):\n",
    "        if token not in word_vectors: \n",
    "            word_vecs.append(oov_vec)\n",
    "        else:\n",
    "            word_vecs.append(word_vectors[token].astype('float64'))\n",
    "    return (np.mean(word_vecs,axis=0)).reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#following embeddingds are used for finding diff distances between question pairs of all vectors\n",
    "all_user_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in all_user_text]) #getting vector representation for user questions\n",
    "all_arch_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in all_arch_text]) #getting vector representation for archived questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting distnces\n",
    "cosine_dist = [cosine_distances(user_quest,arch_quest)[0][0] for user_quest,arch_quest in zip(all_user_vecs,all_arch_vecs)] #getting cosine similarity between pir of questions and saving it in all_text dataframe\n",
    "QApair_df['cosine_dist'] = cosine_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>guid</th>\n",
       "      <th>qu_id</th>\n",
       "      <th>qu</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>qa</th>\n",
       "      <th>ans_id</th>\n",
       "      <th>ans</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>is_correspond</th>\n",
       "      <th>...</th>\n",
       "      <th>f_uq</th>\n",
       "      <th>f_aq</th>\n",
       "      <th>l_uq</th>\n",
       "      <th>l_aq</th>\n",
       "      <th>num_words_uq</th>\n",
       "      <th>num_words_aq</th>\n",
       "      <th>n_common_words</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>fraction_common_words</th>\n",
       "      <th>cosine_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>3589</td>\n",
       "      <td>129727</td>\n",
       "      <td>100851</td>\n",
       "      <td>what is the salary of indian foreign service o...</td>\n",
       "      <td>100852</td>\n",
       "      <td>what is the salary of an indian foreign servic...</td>\n",
       "      <td>32525</td>\n",
       "      <td>While working in India, an IFS officer can dra...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.012714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>4819</td>\n",
       "      <td>3892</td>\n",
       "      <td>172683</td>\n",
       "      <td>what would happen to british empire and its ef...</td>\n",
       "      <td>172684</td>\n",
       "      <td>what would happen if indian people had succeed...</td>\n",
       "      <td>146655</td>\n",
       "      <td>The currency in circulation probably would hav...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>125</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.080617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    guid   qu_id  \\\n",
       "876         3589  129727  100851   \n",
       "1176        4819    3892  172683   \n",
       "\n",
       "                                                     qu   qa_id  \\\n",
       "876   what is the salary of indian foreign service o...  100852   \n",
       "1176  what would happen to british empire and its ef...  172684   \n",
       "\n",
       "                                                     qa  ans_id  \\\n",
       "876   what is the salary of an indian foreign servic...   32525   \n",
       "1176  what would happen if indian people had succeed...  146655   \n",
       "\n",
       "                                                    ans  is_duplicate  \\\n",
       "876   While working in India, an IFS officer can dra...             1   \n",
       "1176  The currency in circulation probably would hav...             1   \n",
       "\n",
       "      is_correspond  ...  f_uq  f_aq  l_uq  l_aq  num_words_uq  num_words_aq  \\\n",
       "876               1  ...     1     2    54    57            10            11   \n",
       "1176              1  ...     1     1   141   125            25            23   \n",
       "\n",
       "      n_common_words  total_word_count  fraction_common_words  cosine_dist  \n",
       "876             10.0              21.0               0.476190     0.012714  \n",
       "1176            16.0              45.0               0.355556     0.080617  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QApair_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'guid', 'qu_id', 'qu', 'qa_id', 'qa', 'ans_id', 'ans',\n",
       "       'is_duplicate', 'is_correspond', 'is_useful', 'f_uq', 'f_aq', 'l_uq',\n",
       "       'l_aq', 'num_words_uq', 'num_words_aq', 'n_common_words',\n",
       "       'total_word_count', 'fraction_common_words', 'cosine_dist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if all columns are present including the columns for all newly create distance features\n",
    "QApair_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = QApair_df[['cosine_dist']].copy()\n",
    "y_data = QApair_df['is_duplicate'].copy()\n",
    "all_cos_dist_scores = QApair_df[\"cosine_dist\"]\n",
    "all_labels = QApair_df[\"is_duplicate\"]\n",
    "train_dist_scores = np.array([sigmoid(x) for x in all_cos_dist_scores]).reshape(-1,1)\n",
    "train_labels = all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression+Word2vec for distance feature+Cosine distance+Sigmoid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Fine tuning Logistic regression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipe = Pipeline([(\"clf\",LogisticRegression())])\n",
    "param_grid = [{\"clf__C\":[0.1,1.0,10.0],\"clf__class_weight\":['dict','balanced'],\"clf__solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \"clf__max_iter\": [1000,2000,5000,10000]}]\n",
    "gs = GridSearchCV(pipe,param_grid,scoring = \"accuracy\",cv = 5, verbose = 1, n_jobs = -1)\n",
    "gs.fit(train_dist_scores,train_labels)\n",
    "#getting the best params from grid search\n",
    "print(\"Best Params\",gs.best_params_)\n",
    "print(\"Best Score\",gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model using best params from grid search\n",
    "clf = LogisticRegression(C = 10,class_weight = 'dict', max_iter = 5000, solver = 'sag').fit(train_dist_scores, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'guid', 'qu_id', 'qu', 'qa_id', 'qa', 'ans_id', 'ans',\n",
       "       'is_duplicate', 'is_correspond', 'is_useful', 'f_uq', 'f_aq', 'l_uq',\n",
       "       'l_aq', 'num_words_uq', 'num_words_aq', 'n_common_words',\n",
       "       'total_word_count', 'fraction_common_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding mean reciprocal rank:\n",
    "test_df_ml = pd.read_csv('test.csv') #getting the test data\n",
    "test_df_ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of archived Questions: 500\n"
     ]
    }
   ],
   "source": [
    "test_df_ml = test_df_ml[['guid', 'qu_id', 'qu', 'qa_id', 'qa', 'ans_id', 'ans','is_duplicate', 'is_correspond', 'is_useful',]].copy()\n",
    "test_df_ml = test_df_ml[:500]\n",
    "l = len(test_df_ml['qa'])#Number of archived Questions\n",
    "print(\"Number of archived Questions:\",l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_questions = test_df_ml['qu'].tolist()\n",
    "LR_WV_S_reciprocal_rank_list = []\n",
    "most_similar_quest_id = 0\n",
    "arch_questions = test_df_ml['qa'].tolist()\n",
    "for uquest_id, user_quest in enumerate(user_questions):\n",
    "    test_ml = test_df_ml[['guid', 'qu_id', 'qa', 'ans_id', 'ans','is_duplicate', 'is_correspond', 'is_useful',]].copy()\n",
    "    test_ml.loc[:,'qu'] = [user_quest]*l #appending user question to all archived questions dataframe\n",
    "    #finding distances\n",
    "    ml_test_user_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in test_ml['qu'].tolist()])\n",
    "    ml_test_arch_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in test_ml['qa'].tolist()])\n",
    "    test_ml['cosine_dist'] = [cosine_distances(user_quest,arch_quest)[0][0] for user_quest,arch_quest in zip(ml_test_user_vecs,ml_test_arch_vecs)] #getting cosine similarity between pir of questions and saving it in all_text dataframe\n",
    "    test_x_data = test_ml[['cosine_dist']].copy()\n",
    "    test_x_data = test_x_data.values #list of cosine similarities\n",
    "    test_x_data_dist = np.array([sigmoid(x) for x in test_x_data]).reshape(-1,1)\n",
    "    y_pred = clf.predict_proba(test_x_data_dist) #predict probability\n",
    "    #print(max(x_data))\n",
    "    y_max = y_pred[:,1] #selecting only probability of duplication\n",
    "    #print(max(y_max))\n",
    "    most_similar_quest_id = np.argmax(np.array(y_max))\n",
    "    #print(most_similar_quest_id)\n",
    "    if arch_questions[uquest_id] ==arch_questions[most_similar_quest_id]:#comparing the retreived with duplicate question of user question\n",
    "        #print(\"\\nMost similar question retrieved\")\n",
    "        LR_WV_S_reciprocal_rank_list.append(1)\n",
    "    else:\n",
    "        #print(\"\\nDissimilar question retrived\")\n",
    "        LR_WV_S_reciprocal_rank_list.append(0)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank for Logistic regression+Basic features+Word2vec  0.594\n",
      "Number of question correctly retreived for Logistic regression+Basic features+Word2Vec  297\n"
     ]
    }
   ],
   "source": [
    "LR_WV_S_mean_reciprocal_rank = np.mean(np.array(LR_WV_S_reciprocal_rank_list))\n",
    "print(\"Mean Reciprocal Rank for Logistic regression+Basic features+Word2vec \",LR_WV_S_mean_reciprocal_rank)\n",
    "print(\"Number of question correctly retreived for Logistic regression+Basic features+Word2Vec \", sum(LR_WV_S_reciprocal_rank_list) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes+Word2Vec for distance Feature+Cosine Distance+Sigmoid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Fine tuning Logistic regression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipe = Pipeline([(\"nb\",MultinomialNB())])\n",
    "param_grid = [{\"nb__alpha\":[0.1,0.2,0.5,1.0,10.0,50,100.0,200,1000]}]\n",
    "gs = GridSearchCV(pipe,param_grid,scoring = \"accuracy\",cv = 5, verbose = 1, n_jobs = -1)\n",
    "gs.fit(train_dist_scores,train_labels)\n",
    "#getting the best params from grid search\n",
    "print(\"Best Params\",gs.best_params_)\n",
    "print(\"Best Score\",gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting with best params\n",
    "nb = MultinomialNB(alpha = 0.1).fit(train_dist_scores,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_questions = test_df_ml['qu'].tolist()\n",
    "NB_WV_S_reciprocal_rank_list = []\n",
    "most_similar_quest_id = 0\n",
    "arch_questions = test_df_ml['qa'].tolist()\n",
    "for uquest_id, user_quest in enumerate(user_questions):\n",
    "    test_ml = test_df_ml[['guid', 'qu_id', 'qa', 'ans_id', 'ans','is_duplicate', 'is_correspond', 'is_useful',]].copy()\n",
    "    test_ml.loc[:,'qu'] = [user_quest]*l #appending user question to all archived questions dataframe\n",
    "    #finding distances\n",
    "    ml_test_user_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in test_ml['qu'].tolist()])\n",
    "    ml_test_arch_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in test_ml['qa'].tolist()])\n",
    "    test_ml['cosine_dist'] = [cosine_distances(user_quest,arch_quest)[0][0] for user_quest,arch_quest in zip(ml_test_user_vecs,ml_test_arch_vecs)] #getting cosine similarity between pir of questions and saving it in all_text dataframe\n",
    "    test_x_data = test_ml[['cosine_dist']].copy()\n",
    "    test_x_data = test_x_data.values #list of cosine similarities\n",
    "    test_x_data_dist = np.array([sigmoid(x) for x in test_x_data]).reshape(-1,1)\n",
    "    y_pred = nb.predict_proba(test_x_data_dist) #predict probability\n",
    "    #print(max(x_data))\n",
    "    y_max = y_pred[:,1] #selecting only probability of duplication\n",
    "    #print(max(y_max))\n",
    "    most_similar_quest_id = np.argmax(np.array(y_max))\n",
    "    #print(most_similar_quest_id)\n",
    "    if arch_questions[uquest_id] ==arch_questions[most_similar_quest_id]:#comparing the retreived with duplicate question of user question\n",
    "        #print(\"\\nMost similar question retrieved\")\n",
    "        NB_WV_S_reciprocal_rank_list.append(1)\n",
    "    else:\n",
    "        #print(\"\\nDissimilar question retrived\")\n",
    "        NB_WV_S_reciprocal_rank_list.append(0)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank for Naivebase+Basic features_Word2Vec  0.002\n",
      "Number of question correctly retreived for Naivebase+Basic features_Word2Vec:  1\n"
     ]
    }
   ],
   "source": [
    "NB_WV_S_mean_reciprocal_rank = np.mean(np.array(NB_WV_S_reciprocal_rank_list))\n",
    "print(\"Mean Reciprocal Rank for Naivebase+Basic features_Word2Vec \",NB_WV_S_mean_reciprocal_rank)\n",
    "print(\"Number of question correctly retreived for Naivebase+Basic features_Word2Vec: \", sum(NB_WV_S_reciprocal_rank_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Method3: Logistic regression+Glove for distance feature+Cosine Distance+Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>guid</th>\n",
       "      <th>qu_id</th>\n",
       "      <th>qu</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>qa</th>\n",
       "      <th>ans_id</th>\n",
       "      <th>ans</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>is_correspond</th>\n",
       "      <th>is_useful</th>\n",
       "      <th>f_uq</th>\n",
       "      <th>f_aq</th>\n",
       "      <th>l_uq</th>\n",
       "      <th>l_aq</th>\n",
       "      <th>num_words_uq</th>\n",
       "      <th>num_words_aq</th>\n",
       "      <th>n_common_words</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>fraction_common_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>6964</td>\n",
       "      <td>66901</td>\n",
       "      <td>230109</td>\n",
       "      <td>what is the meaning of an actor tattoo</td>\n",
       "      <td>230108</td>\n",
       "      <td>what does a mountain tattoo mean</td>\n",
       "      <td>195979</td>\n",
       "      <td>Tattoos mean whatever the wearer chooses. A mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>4468</td>\n",
       "      <td>136865</td>\n",
       "      <td>112774</td>\n",
       "      <td>what are the best ways to deal with and or avo...</td>\n",
       "      <td>151350</td>\n",
       "      <td>what exactly is jet lag</td>\n",
       "      <td>214963</td>\n",
       "      <td>I have written an article about Jet Lag, and I...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    guid   qu_id  \\\n",
       "7439        6964   66901  230109   \n",
       "6208        4468  136865  112774   \n",
       "\n",
       "                                                     qu   qa_id  \\\n",
       "7439             what is the meaning of an actor tattoo  230108   \n",
       "6208  what are the best ways to deal with and or avo...  151350   \n",
       "\n",
       "                                    qa  ans_id  \\\n",
       "7439  what does a mountain tattoo mean  195979   \n",
       "6208           what exactly is jet lag  214963   \n",
       "\n",
       "                                                    ans  is_duplicate  \\\n",
       "7439  Tattoos mean whatever the wearer chooses. A mo...             0   \n",
       "6208  I have written an article about Jet Lag, and I...             0   \n",
       "\n",
       "      is_correspond  is_useful  f_uq  f_aq  l_uq  l_aq  num_words_uq  \\\n",
       "7439              1          0     1     1    40    34             9   \n",
       "6208              1          0     2     1    58    25            13   \n",
       "\n",
       "      num_words_aq  n_common_words  total_word_count  fraction_common_words  \n",
       "7439             7             3.0              16.0               0.187500  \n",
       "6208             6             4.0              19.0               0.210526  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QApair_df = pd.read_csv('train.csv')\n",
    "QApair_df = shuffle(QApair_df)\n",
    "QApair_df = QApair_df.dropna() #dropping na\n",
    "QApair_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all text size 8000\n",
      "All label size 8000\n"
     ]
    }
   ],
   "source": [
    "all_text = QApair_df[[\"qu\",\"qa\"]]\n",
    "all_labels = QApair_df[\"is_duplicate\"]\n",
    "print(\"all text size\", len(all_text))\n",
    "print(\"All label size\", len(all_labels))\n",
    "all_user_text = all_text[\"qu\"].tolist() # user question to list\n",
    "all_arch_text = all_text[\"qa\"].tolist() #archived question to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_vectors #deleting already loaded wordvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# here I load the 300-dimension vectors; loading longer embeddings would require longer time and more RAM\n",
    "path_of_downloaded_files = \"C:\\\\Users\\\\ASUS\\\\NLP\\\\embeddings\\\\glove.6B\\\\glove.6B.300d.txt\" \n",
    "\n",
    "glove_file = datapath(path_of_downloaded_files)\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.300d.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_dim = 300 # this number should match the embedding used\n",
    "oov_vec = np.random.rand(word_vec_dim) \n",
    "def vectorize_sent(word_vectors, sent):\n",
    "    word_vecs = []\n",
    "    for token in word_tokenize(sent):\n",
    "        if token not in word_vectors: \n",
    "            word_vecs.append(oov_vec)\n",
    "        else:\n",
    "            word_vecs.append(word_vectors[token].astype('float64'))\n",
    "    return (np.mean(word_vecs,axis=0)).reshape(1,-1)\n",
    "\n",
    "vv = vectorize_sent(word_vectors, 'hello world ! this is a test sentence !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#following embeddingds are used for finding diff distances between question pairs of all vectors\n",
    "all_user_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in all_user_text]) #getting vector representation for user questions\n",
    "all_arch_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in all_arch_text]) #getting vector representation for archived questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting distnces\n",
    "cosine_dist = [cosine_distances(user_quest,arch_quest)[0][0] for user_quest,arch_quest in zip(all_user_vecs,all_arch_vecs)] #getting cosine similarity between pir of questions and saving it in all_text dataframe\n",
    "QApair_df['cosine_dist'] = cosine_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>guid</th>\n",
       "      <th>qu_id</th>\n",
       "      <th>qu</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>qa</th>\n",
       "      <th>ans_id</th>\n",
       "      <th>ans</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>is_correspond</th>\n",
       "      <th>...</th>\n",
       "      <th>f_uq</th>\n",
       "      <th>f_aq</th>\n",
       "      <th>l_uq</th>\n",
       "      <th>l_aq</th>\n",
       "      <th>num_words_uq</th>\n",
       "      <th>num_words_aq</th>\n",
       "      <th>n_common_words</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>fraction_common_words</th>\n",
       "      <th>cosine_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>6964</td>\n",
       "      <td>66901</td>\n",
       "      <td>230109</td>\n",
       "      <td>what is the meaning of an actor tattoo</td>\n",
       "      <td>230108</td>\n",
       "      <td>what does a mountain tattoo mean</td>\n",
       "      <td>195979</td>\n",
       "      <td>Tattoos mean whatever the wearer chooses. A mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.163312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>4468</td>\n",
       "      <td>136865</td>\n",
       "      <td>112774</td>\n",
       "      <td>what are the best ways to deal with and or avo...</td>\n",
       "      <td>151350</td>\n",
       "      <td>what exactly is jet lag</td>\n",
       "      <td>214963</td>\n",
       "      <td>I have written an article about Jet Lag, and I...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    guid   qu_id  \\\n",
       "7439        6964   66901  230109   \n",
       "6208        4468  136865  112774   \n",
       "\n",
       "                                                     qu   qa_id  \\\n",
       "7439             what is the meaning of an actor tattoo  230108   \n",
       "6208  what are the best ways to deal with and or avo...  151350   \n",
       "\n",
       "                                    qa  ans_id  \\\n",
       "7439  what does a mountain tattoo mean  195979   \n",
       "6208           what exactly is jet lag  214963   \n",
       "\n",
       "                                                    ans  is_duplicate  \\\n",
       "7439  Tattoos mean whatever the wearer chooses. A mo...             0   \n",
       "6208  I have written an article about Jet Lag, and I...             0   \n",
       "\n",
       "      is_correspond  ...  f_uq  f_aq  l_uq  l_aq  num_words_uq  num_words_aq  \\\n",
       "7439              1  ...     1     1    40    34             9             7   \n",
       "6208              1  ...     2     1    58    25            13             6   \n",
       "\n",
       "      n_common_words  total_word_count  fraction_common_words  cosine_dist  \n",
       "7439             3.0              16.0               0.187500     0.163312  \n",
       "6208             4.0              19.0               0.210526     0.210024  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QApair_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'guid', 'qu_id', 'qu', 'qa_id', 'qa', 'ans_id', 'ans',\n",
       "       'is_duplicate', 'is_correspond', 'is_useful', 'f_uq', 'f_aq', 'l_uq',\n",
       "       'l_aq', 'num_words_uq', 'num_words_aq', 'n_common_words',\n",
       "       'total_word_count', 'fraction_common_words', 'cosine_dist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if all columns are present including the columns for all newly create distance features\n",
    "QApair_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = QApair_df[['cosine_dist']].copy()\n",
    "y_data = QApair_df['is_duplicate'].copy()\n",
    "all_cos_dist_scores = QApair_df[\"cosine_dist\"]\n",
    "all_labels = QApair_df[\"is_duplicate\"]\n",
    "train_dist_scores = np.array([sigmoid(x) for x in all_cos_dist_scores]).reshape(-1,1)\n",
    "train_labels = all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression+Glove for distance feature+Cosine distance+Sigmoid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Fine tuning Logistic regression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipe = Pipeline([(\"clf\",LogisticRegression())])\n",
    "param_grid = [{\"clf__C\":[0.1,1.0,10.0],\"clf__class_weight\":['dict','balanced'],\"clf__solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \"clf__max_iter\": [1000,2000,5000,10000]}]\n",
    "gs = GridSearchCV(pipe,param_grid,scoring = \"accuracy\",cv = 5, verbose = 1, n_jobs = -1)\n",
    "gs.fit(train_dist_scores,train_labels)\n",
    "#getting the best params from grid search\n",
    "print(\"Best Params\",gs.best_params_)\n",
    "print(\"Best Score\",gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model using best params from grid search\n",
    "clf = LogisticRegression(C = 10,class_weight = 'dict', max_iter = 5000, solver = 'sag').fit(train_dist_scores, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'guid', 'qu_id', 'qu', 'qa_id', 'qa', 'ans_id', 'ans',\n",
       "       'is_duplicate', 'is_correspond', 'is_useful', 'f_uq', 'f_aq', 'l_uq',\n",
       "       'l_aq', 'num_words_uq', 'num_words_aq', 'n_common_words',\n",
       "       'total_word_count', 'fraction_common_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding mean reciprocal rank:\n",
    "test_df_ml = pd.read_csv('test.csv') #getting the test data\n",
    "test_df_ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of archived Questions: 500\n"
     ]
    }
   ],
   "source": [
    "test_df_ml = test_df_ml[['guid', 'qu_id', 'qu', 'qa_id', 'qa', 'ans_id', 'ans','is_duplicate', 'is_correspond', 'is_useful',]].copy()\n",
    "test_df_ml = test_df_ml[:500]\n",
    "l = len(test_df_ml['qa'])#Number of archived Questions\n",
    "print(\"Number of archived Questions:\",l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_questions = test_df_ml['qu'].tolist()\n",
    "LR_G_S_reciprocal_rank_list = []\n",
    "most_similar_quest_id = 0\n",
    "arch_questions = test_df_ml['qa'].tolist()\n",
    "for uquest_id, user_quest in enumerate(user_questions):\n",
    "    test_ml = test_df_ml[['guid', 'qu_id', 'qa', 'ans_id', 'ans','is_duplicate', 'is_correspond', 'is_useful',]].copy()\n",
    "    test_ml.loc[:,'qu'] = [user_quest]*l #appending user question to all archived questions dataframe\n",
    "    #finding distances\n",
    "    ml_test_user_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in test_ml['qu'].tolist()])\n",
    "    ml_test_arch_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in test_ml['qa'].tolist()])\n",
    "    test_ml['cosine_dist'] = [cosine_distances(user_quest,arch_quest)[0][0] for user_quest,arch_quest in zip(ml_test_user_vecs,ml_test_arch_vecs)] #getting cosine similarity between pir of questions and saving it in all_text dataframe\n",
    "    test_x_data = test_ml[['cosine_dist']].copy()\n",
    "    test_x_data = test_x_data.values #list of cosine similarities\n",
    "    test_x_data_dist = np.array([sigmoid(x) for x in test_x_data]).reshape(-1,1)\n",
    "    y_pred = clf.predict_proba(test_x_data_dist) #predict probability\n",
    "    #print(max(x_data))\n",
    "    y_max = y_pred[:,1] #selecting only probability of duplication\n",
    "    #print(max(y_max))\n",
    "    most_similar_quest_id = np.argmax(np.array(y_max))\n",
    "    #print(most_similar_quest_id)\n",
    "    if arch_questions[uquest_id] ==arch_questions[most_similar_quest_id]:#comparing the retreived with duplicate question of user question\n",
    "        #print(\"\\nMost similar question retrieved\")\n",
    "        LR_G_S_reciprocal_rank_list.append(1)\n",
    "    else:\n",
    "        #print(\"\\nDissimilar question retrived\")\n",
    "        LR_G_S_reciprocal_rank_list.append(0)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank for Logistic regression+Basic features+Word2vec  0.792\n",
      "Number of question correctly retreived for Logistic regression+Basic features+Word2Vec  396\n"
     ]
    }
   ],
   "source": [
    "LR_G_S_mean_reciprocal_rank = np.mean(np.array(LR_G_S_reciprocal_rank_list))\n",
    "print(\"Mean Reciprocal Rank for Logistic regression+Basic features+Word2vec \",LR_G_S_mean_reciprocal_rank)\n",
    "print(\"Number of question correctly retreived for Logistic regression+Basic features+Word2Vec \", sum(LR_G_S_reciprocal_rank_list) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes+Word2Vec for distance Feature+Cosine Distance+Sigmoid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Fine tuning Logistic regression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipe = Pipeline([(\"nb\",MultinomialNB())])\n",
    "param_grid = [{\"nb__alpha\":[0.1,0.2,0.5,1.0,10.0,50,100.0,200,1000]}]\n",
    "gs = GridSearchCV(pipe,param_grid,scoring = \"accuracy\",cv = 5, verbose = 1, n_jobs = -1)\n",
    "gs.fit(train_dist_scores,train_labels)\n",
    "#getting the best params from grid search\n",
    "print(\"Best Params\",gs.best_params_)\n",
    "print(\"Best Score\",gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting with best params\n",
    "nb = MultinomialNB(alpha = 0.1).fit(train_dist_scores,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_questions = test_df_ml['qu'].tolist()\n",
    "NB_G_S_reciprocal_rank_list = []\n",
    "most_similar_quest_id = 0\n",
    "arch_questions = test_df_ml['qa'].tolist()\n",
    "for uquest_id, user_quest in enumerate(user_questions):\n",
    "    test_ml = test_df_ml[['guid', 'qu_id', 'qa', 'ans_id', 'ans','is_duplicate', 'is_correspond', 'is_useful',]].copy()\n",
    "    test_ml.loc[:,'qu'] = [user_quest]*l #appending user question to all archived questions dataframe\n",
    "    #finding distances\n",
    "    ml_test_user_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in test_ml['qu'].tolist()])\n",
    "    ml_test_arch_vecs = np.array([vectorize_sent(word_vectors, ss) for ss in test_ml['qa'].tolist()])\n",
    "    test_ml['cosine_dist'] = [cosine_distances(user_quest,arch_quest)[0][0] for user_quest,arch_quest in zip(ml_test_user_vecs,ml_test_arch_vecs)] #getting cosine similarity between pir of questions and saving it in all_text dataframe\n",
    "    test_x_data = test_ml[['cosine_dist']].copy()\n",
    "    test_x_data = test_x_data.values #list of cosine similarities\n",
    "    test_x_data_dist = np.array([sigmoid(x) for x in test_x_data]).reshape(-1,1)\n",
    "    y_pred = nb.predict_proba(test_x_data_dist) #predict probability\n",
    "    #print(max(x_data))\n",
    "    y_max = y_pred[:,1] #selecting only probability of duplication\n",
    "    #print(max(y_max))\n",
    "    most_similar_quest_id = np.argmax(np.array(y_max))\n",
    "    #print(most_similar_quest_id)\n",
    "    if arch_questions[uquest_id] ==arch_questions[most_similar_quest_id]:#comparing the retreived with duplicate question of user question\n",
    "        #print(\"\\nMost similar question retrieved\")\n",
    "        NB_G_S_reciprocal_rank_list.append(1)\n",
    "    else:\n",
    "        #print(\"\\nDissimilar question retrived\")\n",
    "        NB_G_S_reciprocal_rank_list.append(0)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank for Naivebase+Basic features_Word2Vec  0.002\n",
      "Number of question correctly retreived for Naivebase+Basic features_Word2Vec:  1\n"
     ]
    }
   ],
   "source": [
    "NB_G_S_mean_reciprocal_rank = np.mean(np.array(NB_G_S_reciprocal_rank_list))\n",
    "print(\"Mean Reciprocal Rank for Naivebase+Basic features_Word2Vec \",NB_G_S_mean_reciprocal_rank)\n",
    "print(\"Number of question correctly retreived for Naivebase+Basic features_Word2Vec: \", sum(NB_G_S_reciprocal_rank_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>mean_reciprocal_ranks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR+WV+CD+S</td>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+WV+CD+S</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR+Glove+CD+S</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+Glove+CD+S</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method  mean_reciprocal_ranks\n",
       "0     LR+WV+CD+S                  0.594\n",
       "1     NB+WV+CD+S                  0.002\n",
       "2  LR+Glove+CD+S                  0.792\n",
       "3  NB+Glove+CD+S                  0.002"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df[\"Method\"] = [\"LR+WV+CD+S\",\"NB+WV+CD+S\",\"LR+Glove+CD+S\",\"NB+Glove+CD+S\"]\n",
    "results_df[\"mean_reciprocal_ranks\"] = [LR_WV_S_mean_reciprocal_rank,NB_WV_S_mean_reciprocal_rank,LR_G_S_mean_reciprocal_rank,NB_G_S_mean_reciprocal_rank]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3],\n",
       " [Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, '')])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(results_df[\"Method\"],results_df[\"mean_reciprocal_ranks\"])\n",
    "plt.ylabel(\"Mean Reciprocal rank\")\n",
    "plt.ylim(0.5,1)\n",
    "plt.xticks(rotation = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vevn_nlp",
   "language": "python",
   "name": "vevn_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
